{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["ho1WU2AnFrwr"],"gpuType":"T4","authorship_tag":"ABX9TyNZgEnqXqO53FSxiaNO/I+l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# This is for the besties that want quick English bases hi there\n","\n","i actually don't know how to setup MFA in here but we're just gonna have to figure that out and by we i mean Me DogeyVOX.\n","\n","also Obviously This Is Gonna Be For English Only. so yeah."],"metadata":{"id":"KMVdr5KmE_xX"}},{"cell_type":"markdown","source":["# Setup Stuff\n","\n","this is gonna install both Whisper and MFA so have fun."],"metadata":{"id":"ho1WU2AnFrwr"}},{"cell_type":"code","source":["#@title Whisper install\n","\n","!pip install -U openai-whisper"],"metadata":{"id":"ddCOuFgqF47S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title MFA install (Part 1)\n","%%writefile install_mfa.sh\n","#!/bin/bash\n","\n","## a script to install Montreal Forced Aligner (MFA)\n","\n","root_dir=${1:-/tmp/mfa}\n","mkdir -p $root_dir\n","cd $root_dir\n","\n","# download miniconda3\n","wget -q --show-progress https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","bash Miniconda3-latest-Linux-x86_64.sh -b -p $root_dir/miniconda3 -f\n","\n","#install MFA\n","$root_dir/miniconda3/bin/conda create -n aligner -c conda-forge montreal-forced-aligner -y\n","\n","echo -e \"\\n======== DONE ==========\"\n","echo -e \"\\nTo activate MFA, run: source $root_dir/miniconda3/bin/activate aligner\"\n","echo -e \"\\nTo delete MFA, run: rm -rf $root_dir\"\n","echo -e \"\\nSee: https://montreal-forced-aligner.readthedocs.io/en/latest/aligning.html to know how to use MFA\""],"metadata":{"id":"F4IfciFNGh7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title MFA install (Part 2)\n","MFA_DIR = '/tmp/mfa'\n","\n","!bash ./install_mfa.sh {MFA_DIR}\n","!source {MFA_DIR}/miniconda3/bin/activate aligner; mfa model download acoustic english_us_arpa; mfa model download dictionary english_us_arpa; mfa model download g2p english_us_arpa"],"metadata":{"id":"eLQ5CwdqG-g5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Other install\n","\n","!pip install tgt"],"metadata":{"id":"2MQSL65zGLQo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Prepare functions\n","\n","import tgt\n","from pathlib import Path\n","from abc import ABC, abstractmethod\n","import librosa\n","\n","class PhonemeConverter(ABC):\n","    @abstractmethod\n","    def invoke(cur, prv=None, nxt=None):\n","        raise NotImplementedError('lol ur phoneme converter isn\\'t working')\n","\n","class ArpabetPlusSchwaPlusTapR(PhonemeConverter):\n","    def invoke(cur, prv=None, nxt=None):\n","        phone = cur.text.lower() # current phoneme\n","        if not phone: # it's silence if it doesn't exist\n","            return 'pau'\n","\n","        if phone in 'dt': # turn d and t to dx if time is less than 0.04 seconds and surrounding phonemes are vowels\n","            if cur.end_time - cur.start_time < 0.04:\n","                if prv and nxt:\n","                    if prv.text and nxt.text:\n","                        if prv.text[-1].isnumeric() and nxt.text[-1].isnumeric():\n","                            return 'dx'\n","\n","        # turn vowels into regular arpa and ah0 to schwa\n","        if phone[-1].isnumeric():\n","            phone = 'ax' if phone == 'ah0' else phone[:-1]\n","        return phone\n","\n","class ArpabetPlusSchwa(PhonemeConverter):\n","    def invoke(cur, prv=None, nxt=None):\n","        phone = cur.text.lower() # current phoneme\n","        if not phone: # it's silence if it doesn't exist\n","            return 'pau'\n","\n","        # turn vowels into regular arpa and ah0 to schwa\n","        if phone[-1].isnumeric():\n","            phone = 'ax' if phone == 'ah0' else phone[:-1]\n","        return phone\n","\n","class RegularArpabet(PhonemeConverter):\n","    def invoke(cur, prv=None, nxt=None):\n","        phone = cur.text.lower() # current phoneme\n","        if not phone: # it's silence if it doesn't exist\n","            return 'pau'\n","\n","        # turn vowels into regular arpa\n","        if phone[-1].isnumeric():\n","            phone = phone[:-1]\n","        return phone\n","\n","class safelist(list):\n","    def get(self, index, default=None):\n","        try:\n","            return self.__getitem__(index)\n","        except IndexError:\n","            return default\n","\n","def whisper_segment_to_interval(segment):\n","    # turn whisper segment into textgrid interval\n","    return tgt.core.Interval(segment['start'], segment['end'], segment['text'])\n","\n","def whisper_words_to_intervals(segment):\n","    # turn whisper segment word timings into textgrid intervals\n","    words = []\n","    for word in segment['words']:\n","        words.append(tgt.core.Interval(word['start'], word['end'], word['word']))\n","    return words\n","\n","def whisper_transcription_to_textgrid(wav_path, transcription, word_level=False):\n","    # turn whisper transcription to textgrid\n","    # get textgrid path\n","    textgrid_path = wav_path.with_suffix('.TextGrid')\n","    wav_length = librosa.get_duration(path=wav_path)\n","\n","    # prepare textgrid and tier\n","    textgrid = tgt.core.TextGrid(str(textgrid_path))\n","    if not word_level:\n","        # make sentence tier\n","        sentence_tier = tgt.core.IntervalTier(end_time=wav_length, name='sentences')\n","\n","        # convert segments to intervals and add\n","        sentence_tier.add_intervals(map(whisper_segment_to_interval, transcription['segments']))\n","\n","        # add tier\n","        textgrid.add_tier(sentence_tier)\n","    else:\n","        # make word tier\n","        word_tier = tgt.core.IntervalTier(end_time=wav_length, name='words')\n","\n","        # convert words from segments to intervals and add\n","        for segment in transcription['segments']:\n","            word_tier.add_intervals(whisper_words_to_intervals(segment))\n","\n","        # add tier\n","        textgrid.add_tier(word_tier)\n","\n","    # write file\n","    tgt.io.write_to_file(textgrid, str(textgrid_path), 'long')\n","\n","def aligned_textgrid_to_lab(textgrid_path, phoneset='ArpabetPlusSchwaPlusTapR'):\n","    # turn MFA aligned textgrid to lab\n","    # get lab path\n","    lab_path = textgrid_path.with_suffix('.lab')\n","\n","    # read textgrid\n","    textgrid = tgt.io.read_textgrid(str(textgrid_path), include_empty_intervals=True)\n","    phoneme_tier = textgrid.get_tier_by_name('phones')\n","    phonemes = safelist(phoneme_tier.annotations)\n","    converter = globals()[phoneset]\n","\n","    # loop through all phonemes and write\n","    with open(lab_path, 'w', encoding='utf8') as f:\n","        for i in range(len(phonemes)):\n","            cur = phonemes[i]\n","            s = int(10000000 * cur.start_time)\n","            e = int(10000000 * cur.end_time)\n","            p = converter.invoke(cur, phonemes.get(i-1), phonemes.get(i+1))\n","            f.write(f'{s} {e} {p}\\n')\n"],"metadata":{"id":"N3deV_FaHQuR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tqh9eokFEpx-"},"outputs":[],"source":["#@title Mount Google Drive\n","\n","from google.colab import drive\n","drive.flush_and_unmount()\n","!rm -rf /content/drive\n","drive.mount('/content/drive')\n","print('Done!')"]},{"cell_type":"markdown","source":["# Dataset Prep\n","\n","i don't wanna do anything fancy so.\n"],"metadata":{"id":"1r6CDe32FYyl"}},{"cell_type":"code","source":["#@title Extract DB\n","\n","#@markdown Only accepting `.7z` or whatever `p7zip` reads sowwy...\n","\n","#@markdown Folder format? nah just put wavs in the thing and it should be fine. it Will move everything in one folder tho so make sure there's no filename clashes.\n","\n","#@markdown if you're doing vocal modes and u find it better to sort by folder make sure u can sort it back again easily. like idk do like `modename_###.wav` or smn.\n","\n","#@markdown filename doesn't matter unless if you have transcriptions/timed transcriptions already the format is the same just make sure the wavs and the txt or textgrids have the same filename\n","import shutil\n","\n","db_zip_loc = '/content/drive/MyDrive/db.7z' #@param {type: \"string\"}\n","\n","db_zip_path = Path(db_zip_loc)\n","db_path = Path('db')\n","wav_path = db_path / 'wav'\n","lab_path = db_path / 'lab'\n","raw_path = Path('raw')\n","\n","if wav_path.exists():\n","    shutil.rmtree(wav_path)\n","\n","wav_path.mkdir(parents=True, exist_ok=True)\n","lab_path.mkdir(parents=True, exist_ok=True)\n","\n","!7za x \"$db_zip_loc\" -o\"raw\"\n","for wav in raw_path.glob('**/*.wav'):\n","    shutil.move(wav, wav_path)\n","\n","for txt in raw_path.glob('**/*.txt'):\n","    shutil.move(txt, wav_path)\n","\n","for tg in raw_path.glob('**/*.TextGrid'):\n","    shutil.move(tg, wav_path)\n","\n","raw_path.rmdir()"],"metadata":{"cellView":"form","id":"EomNKG6LFo2j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Transcription and Forced Alignment\n","\n","this is the fun part"],"metadata":{"id":"YI7Wd3jAtEPH"}},{"cell_type":"code","source":["#@title Whisper Transcription\n","\n","#@markdown this is for those who didn't add their own transcriptions/timed transcriptions\n","\n","#@markdown ---\n","\n","#@markdown ## Parameters\n","#@markdown like the first part says it's english only. `medium.en` gives pretty\n","#@markdown precise labels for word-level, but don't expect it to be that good.\n","#@markdown `base.en` is perfectly fine for sentence-level.\n","#@markdown i haven't tested the multilingual models.\n","model = 'medium.en' #@param [\"tiny.en\", \"base.en\", \"small.en\", \"medium.en\", \"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n","\n","#@markdown this is mostly experimental because word-level timing is a bit weird.\n","word_level_transcription = False #@param {type: \"boolean\"}\n","\n","#@markdown just some funny params that i can expose but i don't exactly recommend changing ig\n","compression_ratio_threshold = 2.4 #@param {type: \"number\"}\n","log_prob_threshold = -1.0 #@param {type: \"number\"}\n","no_speech_threshold = 0.6 #@param {type: \"number\"}\n","condition_on_previous_text = True #@param {type: \"boolean\"}\n","verbose = True #@param {type: \"boolean\"}\n","\n","import whisper\n","\n","whisper_model = whisper.load_model(model)\n","\n","for wav in wav_path.glob('*.wav'):\n","    print(f'Transcribing {wav}')\n","    transcription = whisper_model.transcribe(str(wav),\n","                                             compression_ratio_threshold=compression_ratio_threshold,\n","                                             logprob_threshold = log_prob_threshold,\n","                                             no_speech_threshold = no_speech_threshold,\n","                                             condition_on_previous_text=condition_on_previous_text,\n","                                             word_timestamps=word_level_transcription,\n","                                             verbose=verbose,\n","                                             language='en')\n","\n","    whisper_transcription_to_textgrid(wav, transcription, word_level=word_level_transcription)\n","\n","print('\\nWhisper Transcription: Done.')"],"metadata":{"cellView":"form","id":"F1s6GgAttLs2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title MFA Validate\n","\n","#@markdown this is to check if mfa is being silly and not wanting to read some of ur wavs. if it misses some files i really don't know why it does so i can't help with that sorry.\n","!source {MFA_DIR}/miniconda3/bin/activate aligner; mfa validate --single_speaker --ignore_acoustics db/wav english_us_arpa"],"metadata":{"cellView":"form","id":"MItiqsdjtYHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title MFA Forced Alignment\n","\n","#@markdown this is what turns the whisper transcriptions into silly phoneme-level labels. mind you this is trained on speech so it does kinda not slay sometimes.\n","\n","#@markdown ---\n","\n","#@markdown ## Parameters\n","#@markdown these are the only params i care about lol beam is how big the search is and retry beam is a bigger search when mfa thinks it flopped\n","\n","beam_size = 1000 #@param {type: \"integer\"}\n","retry_beam_size = 4000 #@param {type: \"integer\"}\n","!source {MFA_DIR}/miniconda3/bin/activate aligner; \\\n","mfa g2p db/wav english_us_arpa oov.txt --dictionary_path english_us_arpa; \\\n","mfa model add_words english_us_arpa oov.txt; \\\n","mfa align --fine_tune --single_speaker --textgrid_cleanup db/wav english_us_arpa english_us_arpa db/lab --beam {beam_size} --retry_beam {retry_beam_size}"],"metadata":{"id":"_Jbc_uDH9kyV","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title TextGrid conversion\n","\n","#@markdown this is to convert the format the MFA makes cuz duh we're in `.lab` gang\n","\n","phoneset = 'regular arpabet' #@param [\"regular arpabet\", \"arpabet + schwa\", \"arpabet + schwa + tap r\"]\n","phoneset = ''.join(map(lambda x : x[0].upper() + x[1:], phoneset.replace('+', 'plus').split()))\n","\n","for tg in lab_path.glob('*.TextGrid'):\n","    aligned_textgrid_to_lab(tg, phoneset=phoneset)"],"metadata":{"cellView":"form","id":"Y6eNqw27-u61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Save to Drive\n","\n","#@markdown cuz drive downloads are faster.\n","keep_textgrids = False #@param {type: \"boolean\"}\n","\n","if not keep_textgrids:\n","    for tg in db_path.glob('**/*.TextGrid'):\n","        tg.unlink()\n","\n","labeled_db_path = db_zip_path.with_stem(db_zip_path.stem + '_labeled')\n","labeled_db_loc = str(labeled_db_path)\n","!7za a \"$labeled_db_loc\" \"db\""],"metadata":{"cellView":"form","id":"cn8_Mog8AQCm"},"execution_count":null,"outputs":[]}]}