{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZNaX56xNncdVZbA/VyOoM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Welcome to the CeVOX ENUNU/NNSVS Training Notebook!\n","\n","*Last update: `2022-12-10 12:25 (YYYY-MM-DD hh[24]:mm GMT+8)`* \n","\n","**NOTE:** This notebook is using NNSVS v0.0.3 to compensate for ENUNU. Hopefully ENUNU catches up soon but I'm not gonna get my hopes up that much !\n","\n","This notebook is made by DogeyVOX"],"metadata":{"id":"uP1CT6Say3OA"}},{"cell_type":"markdown","source":["# Check Setup"],"metadata":{"id":"QsSe5qrrz2-3"}},{"cell_type":"code","source":["#@title Check GPU Type\n","\n","#@markdown Google usually gives T4s now so there's nothing to really worry about but hey !\n","\n","!nvidia-smi -L\n","!nvidia-smi"],"metadata":{"cellView":"form","id":"5FdkHF1Y0CB-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Mount Google Drive\n","\n","#@markdown This makes things easy so just do it.\n","\n","from google.colab import drive\n","drive.flush_and_unmount()\n","!rm -rf /content/drive\n","drive.mount('/content/drive')\n","print('Done!')"],"metadata":{"cellView":"form","id":"Akvurazt053A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preparation"],"metadata":{"id":"P6bf91vT133v"}},{"cell_type":"code","source":["#@title # Step 1: Install training kit\n","\n","#@markdown You obviously just run this once.\n","\n","from IPython.display import clear_output\n","\n","print('Installing prerequisites.')\n","!rm -rf /content/sample_data\n","!python -m pip install --upgrade wheel\n","!apt-get install p7zip-full\n","%pip install numpy cython utaupy tqdm pydub pyyaml natsort mlflow optuna hydra-optuna-sweeper\n","%pip install git+https://github.com/MattShannon/bandmat\n","clear_output()\n","\n","print('Installing PyTorch.')\n","%pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio===0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n","%pip install hydra-core<1.1\n","clear_output()\n","\n","print('Downloading ENUNU training kit.')\n","!git clone https://github.com/UtaUtaUtau/enunu_training_kit/\n","clear_output()\n","\n","import yaml\n","\n","def load_yaml(location):\n","    res = None\n","    with open(location) as f:\n","        res = yaml.safe_load(f)\n","    return res\n","\n","def write_yaml(data, location):\n","    with open(location, 'w', encoding='utf8') as f:\n","        yaml.dump(data, f, default_flow_style=False, allow_unicode=True, sort_keys=False)\n","\n","def represent_none(self, _):\n","    return self.represent_scalar('tag:yaml.org,2002:null', '')\n","\n","yaml.add_representer(type(None), represent_none)\n","\n","enunu_base = '/content/enunu_training_kit/train'\n","acoustic_base = enunu_base + '/conf/train/acoustic'\n","duration_base = enunu_base + '/conf/train/duration'\n","timelag_base = enunu_base + '/conf/train/timelag'\n","postfilter_base = enunu_base + '/conf/train/postfilter'\n","\n","config = load_yaml(enunu_base + '/config.yaml')\n","enuconfig = load_yaml(enunu_base + '/enuconfig.yaml')\n","acoustic = load_yaml(acoustic_base + '/model/acoustic_custom.yaml')\n","acoustic_data = load_yaml(acoustic_base + '/data/myconfig.yaml')\n","acoustic_train = load_yaml(acoustic_base + '/train/myconfig.yaml')\n","\n","duration = load_yaml(duration_base + '/model/duration_custom.yaml')\n","duration_data = load_yaml(duration_base + '/data/myconfig.yaml')\n","duration_train = load_yaml(duration_base + '/train/myconfig.yaml')\n","\n","timelag = load_yaml(timelag_base + '/model/timelag_custom.yaml')\n","timelag_data = load_yaml(timelag_base + '/data/myconfig.yaml')\n","timelag_train = load_yaml(timelag_base + '/train/myconfig.yaml')\n","\n","postfilter_mgc = load_yaml(postfilter_base + '/model/postfilter_mgc.yaml')\n","postfilter_bap = load_yaml(postfilter_base + '/model/postfilter_bap.yaml')\n","postfilter_data = load_yaml(postfilter_base + '/data/myconfig.yaml')\n","postfilter_mgc_train = load_yaml(postfilter_base + '/train/mgc.yaml')\n","postfilter_bap_train = load_yaml(postfilter_base + '/train/bap.yaml')\n","\n","print('Installing NNSVS')\n","%pip install https://github.com/nnsvs/nnsvs/archive/refs/tags/v0.0.3.zip\n","clear_output()\n","print('Done!')"],"metadata":{"cellView":"form","id":"lHyCHa0j19uB","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1656230183124,"user_tz":-480,"elapsed":336935,"user":{"displayName":"UtaUtaUtau omg","userId":"02987610874144277075"}},"outputId":"8940b87e-3c83-422c-b493-efcbb3ba58e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Done!\n"]}]},{"cell_type":"code","source":["#@title # Step 2: Decompress dataset\n","\n","#@markdown This'll deal with COMMON archive types so don't worry about anything.\n","\n","#@markdown Supported types: `.rar`, `.zip`, `.tar`, `.tar.gz`, `.tar.bz2`, `.7z`\n","\n","#@markdown ---\n","#@markdown Empty dataset folder if ig u made a mistake.\n","\n","empty_dataset_folder = False #@param {type: \"boolean\"}\n","\n","#@markdown File location stuff. You know the drill. It's case sensitive.\n","dataset_loc = '/content/drive/MyDrive/database.*' #@param {type: \"string\"}\n","enunu_loc = '/content/enunu_training_kit/train/singing_database'\n","\n","#@markdown ---\n","\n","#@markdown Sample rate is a requirement now so\n","sample_rate = \"44100\" #@param [44100, 48000]\n","\n","config['sample_rate'] = int(sample_rate)\n","enuconfig['sample_rate'] = int(sample_rate)\n","write_yaml(config, enunu_base + '/config.yaml')\n","write_yaml(enuconfig, enunu_base + '/enuconfig.yaml')\n","\n","import os\n","\n","if empty_dataset_folder:\n","    !rm -rf \"$enunu_loc\"\n","\n","if not os.path.exists(enunu_loc):\n","    !mkdir \"$enunu_loc\"\n","\n","if dataset_loc.endswith('.rar'):\n","    !unrar x \"$dataset_loc\" \"$enunu_loc\"\n","elif dataset_loc.endswith('.zip'):\n","    !unzip \"$dataset_loc\" -d \"$enunu_loc\"\n","elif dataset_loc.endswith('.tar'):\n","    !tar -xf \"$dataset_loc\" -C \"$enunu_loc\"\n","elif dataset_loc.endswith('.tar.gz'):\n","    !tar -xzf \"$dataset_loc\" -C \"$enunu_loc\"\n","elif dataset_loc.endswith('.tar.bz2'):\n","    !tar -xjf \"$dataset_loc\" -C \"$enunu_loc\"\n","else:\n","    !7za x \"$dataset_loc\" -o$enunu_loc\n","\n","print('Done!')"],"metadata":{"id":"vZqtz0SoC5nS","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training Options/Parameters\n","\n","These are lowkey not optional so yeah."],"metadata":{"id":"8KLh9qk9MxAd"}},{"cell_type":"code","source":["#@title # Step 3: Set Language\n","\n","#@markdown Set the language for your model or something.\n","\n","#@markdown Mode guide:\n","#@markdown - Default: Default Japanese\n","#@markdown - Custom: Get from a directory\n","#@markdown - Archive: Get from an archive. `.zip` only\n","#@markdown - GitHub: Get from a GitHub repository\n","mode = \"Custom\" #@param [\"Default\", \"Custom\", \"Archive\", \"GitHub\"]\n","\n","#@markdown ---\n","#@markdown ### The location of the custom .hed and .table\n","\n","#@markdown Can be a .zip location, a directory, or a GitHub repo.\n","lang_loc = '/content/drive/MyDrive/whatever.*' #@param {type: \"string\"}\n","\n","#@markdown ---\n","#@markdown ### Filenames of .hed and .table\n","\n","hed_file = 'Custom_HED.hed' #@param {type: \"string\"}\n","table_file = 'dict.table' #@param {type: \"string\"}\n","\n","#@markdown ---\n","#@markdown ### Vowels of the language\n","\n","vowel_list = 'a, i, u, e, o, A, I, U, E, O, N' #@param {type: \"string\"}\n","vowels = vowel_list.split(',')\n","\n","import os, shutil\n","from nnmnkwii.io import hts\n","\n","def find_language_files(location):\n","    for root, dirs, files in os.walk(location):\n","        for f in files:\n","            full_path = os.path.join(root, f)\n","            if f == hed_file:\n","                shutil.copy(full_path, enunu_base + '/hed')\n","            if f == table_file:\n","                shutil.copy(full_path, enunu_base + '/dic')\n","\n","if mode == 'Default':\n","    hed_file = 'jp_qst_crazy_mono_013_enunu_221D.hed'\n","    table_file = 'kana2phonemes_002_oto2lab.table'\n","    vowels = ['a', 'i', 'u', 'e', 'o', 'A', 'I', 'U', 'E', 'O', 'N']\n","elif mode == 'Custom':\n","    find_language_files(lang_loc)\n","elif mode == 'Archive':\n","    !unzip \"$lang_loc\" -d /content/custom_lang\n","    find_language_files('/content/custom_lang')\n","    !rm -rf /content/custom_lang\n","elif mode == 'GitHub':\n","    !git clone \"$lang_loc\" /content/custom_lang\n","    find_language_files('/content/custom_lang')\n","    !rm -rf /content/custom_lang\n","    \n","in_dim = 0\n","\n","binary, continuous = hts.load_question_set(enunu_base + '/hed/' + hed_file)\n","in_dim = len(binary) + len(continuous)\n","\n","print('in_dim: ', in_dim)\n","\n","for i in range(len(vowels)):\n","    vowels[i] = \"'\" + vowels[i].strip().replace(\"'\", \"\\\\'\") + \"'\"\n","\n","script = open(enunu_base + '/stage0/compare_mono_align_and_mono_score.py').readlines()\n","\n","with open(enunu_base + '/stage0/compare_mono_align_and_mono_score.py', 'w', encoding = 'utf8') as f:\n","    for i in script:\n","        if i.startswith('VOWELS = '):\n","            f.write('VOWELS = {' + ', '.join(vowels) + '}\\n')\n","        else:\n","            f.write(i)\n","\n","config['table_path'] = 'dic/' + table_file\n","config['question_path'] = 'hed/' + hed_file\n","enuconfig['table_path'] = 'dic/' + table_file\n","enuconfig['question_path'] = 'hed/' + hed_file\n","\n","acoustic['netG']['in_dim'] = in_dim + 4\n","duration['netG']['in_dim'] = in_dim\n","timelag['netG']['in_dim'] = in_dim\n","\n","write_yaml(acoustic, acoustic_base + '/model/acoustic_custom.yaml')\n","write_yaml(duration, duration_base + '/model/duration_custom.yaml')\n","write_yaml(timelag, timelag_base + '/model/timelag_custom.yaml')\n","\n","write_yaml(config, enunu_base + '/config.yaml')\n","write_yaml(enuconfig, enunu_base + '/enuconfig.yaml')"],"metadata":{"id":"6Aie-XwwM7_0","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title # Step 4: Change Model Type\n","\n","#@markdown Some of these models might not work in ENUNU, but I just added them cuz why not !\n","\n","acoustic_model = 'Conv1dResnet' #@param [\"Conv1dResnet\", \"FeedForwardNet\", \"LSTMRNN\", \"LSTMRNNSAR\", \"Conv1dResnetSAR\", \"MDN\", \"MDNv2\", \"RMDN\", \"FFConvLSTM\", \"VariancePredictor\", \"ResF0Conv1dResnet\", \"ResSkipF0FFConvLSTM\", \"ResF0VariancePredictor\"]\n","duration_model = 'MDN' #@param [\"LSTMRNN\", \"LSTMRNNSAR\", \"FeedForwardNet\", \"MDN\", \"MDNv2\", \"RMDN\"]\n","timelag_model = 'MDN' #@param [\"FeedForwardNet\", \"MDN\", \"MDNv2\", \"RMDN\"]\n","\n","#@markdown ---\n","\n","#@markdown ### Vibrato Modeling\n","\n","#@markdown Yeah. Vibrato... idk how to explain it.\n","\n","vibrato_mode = 'none' #@param [\"none\", \"sine\", \"diff\"]\n","\n","#@markdown ---\n","\n","#@markdown ### Initalization Type\n","\n","#@markdown Acoustic might train better with an init_type.\n","\n","acoustic_init = 'kaiming_normal' #@param [\"none\", \"kaiming_normal\", \"xavier_normal\"]\n","duration_init = 'none' #@param [\"none\", \"kaiming_normal\", \"xavier_normal\"]\n","timelag_init = 'none' #@param [\"none\", \"kaiming_normal\", \"xavier_normal\"]\n","\n","#@markdown ---\n","\n","#@markdown ### Feats Criterion/Loss Function\n","\n","#@markdown L1/MAE loss seems to work better generally.\n","\n","#@markdown **Disclaimer:** MAE loss seems to drop vibrato. This isn't completely confirmed so you're free to try anyways.\n","\n","acoustic_criterion = 'mae' #@param [\"mse\", \"mae\"]\n","duration_criterion = 'mae' #@param [\"mse\", \"mae\"]\n","timelag_criterion = 'mae' #@param [\"mse\", \"mae\"]\n","\n","#@markdown ---\n","\n","#@markdown This option is for `Conv1dResnet`, `VariancePredictor` and ResF0 models only.\n","\n","use_mdn = False #@param {type : \"boolean\"}\n","\n","#@markdown ---\n","\n","#@markdown ###This part is for ResF0 models only.\n","\n","#@markdown Specify which part of the HED file is the central silences. It's automatically dealt with for the Japanese Default HED tho so no worries in that case.\n","\n","silences = 'C-Phone_Silences' #@param {type : \"string\"}\n","\n","#@markdown Okay apparently this is pitch regularization.\n","pitch_reg = 1.0 #@param {type : \"number\"}\n","#@markdown This tells how big the smoothing is or smn.\n","pitch_reg_decay_size = 15 #@param {type : \"integer\"}\n","\n","#Set models\n","acoustic['netG']['_target_'] = 'nnsvs.model.' + acoustic_model\n","duration['netG']['_target_'] = 'nnsvs.model.' + duration_model\n","timelag['netG']['_target_'] = 'nnsvs.model.' + timelag_model\n","\n","#Set feats_criterion for each model.\n","acoustic_train['feats_criterion'] = acoustic_criterion\n","duration_train['feats_criterion'] = duration_criterion\n","timelag_train['feats_criterion'] = timelag_criterion\n","\n","#Set init type and remove if it's none.\n","if acoustic_init == 'none':\n","    if 'init_type' in acoustic['netG'].keys():\n","        del acoustic['netG']['init_type']\n","else:\n","    acoustic['netG']['init_type'] = acoustic_init\n","\n","if duration_init == 'none':\n","    if 'init_type' in duration['netG'].keys():\n","        del duration['netG']['init_type']\n","else:\n","    duration['netG']['init_type'] = duration_init\n","\n","if timelag_init == 'none':\n","    if 'init_type' in timelag['netG'].keys():\n","        del timelag['netG']['init_type']\n","else:\n","    timelag['netG']['init_type'] = timelag_init\n","\n","#Set use_mdn for models that use them, remove them if not.\n","if acoustic_model in ['Conv1dResnet', 'VariancePredictor'] or acoustic_model.startswith('Res'):\n","    acoustic['netG']['use_mdn'] = use_mdn\n","    if use_mdn:\n","        acoustic['netG']['dim_wise'] = True\n","        acoustic_train['use_detect_anomaly'] = False\n","    else:\n","        acoustic_train['use_detect_anomaly'] = True\n","else:\n","    if 'use_mdn' in acoustic['netG'].keys():\n","        del acoustic['netG']['use_mdn']\n","    if 'dim_wise' in acoustic['netG'].keys():\n","        del acoustic['netG']['dim_wise']\n","    acoustic_train['use_detect_anomaly'] = True\n","\n","#Set things for MDN acoustic\n","if 'MDN' in acoustic_model or use_mdn:\n","    acoustic['netG']['dim_wise'] = True\n","    acoustic_train['use_detect_anomaly'] = False\n","else:\n","    if 'dim_wise' in acoustic['netG'].keys():\n","        del acoustic['netG']['dim_wise']\n","    acoustic_train['use_detect_anomaly'] = True\n","\n","#Set bidirectional for LSTM/RNN models, remove if not.\n","if 'LSTM' in acoustic_model or acoustic_model == 'RMDN':\n","    acoustic['netG']['bidirectional'] = True\n","else:\n","    if 'bidirectional' in acoustic['netG'].keys():\n","        del acoustic['netG']['bidirectional']\n","\n","if 'LSTM' in duration_model or duration_model == 'RMDN':\n","    duration['netG']['bidirectional'] = True\n","else:\n","    if 'bidirectional' in duration['netG'].keys():\n","        del duration['netG']['bidirectional']\n","\n","if 'LSTM' in timelag_model or timelag_model == 'RMDN':\n","    timelag['netG']['bidirectional'] = True\n","else:\n","    if 'bidirectional' in timelag['netG'].keys():\n","        del timelag['netG']['bidirectional']\n","\n","#Deal with ResF0 models.\n","if acoustic_model.startswith('Res'):\n","    if mode == 'Default':\n","        silences = 'p4_C-Phone_Muon'\n","    \n","    in_rest_idx = 0\n","    in_lf0_idx = 0\n","\n","    for n in range(len(binary)):\n","        if binary[n][0] == silences:\n","            in_rest_idx = n\n","            break\n","\n","    for n in range(len(continuous)):\n","        if continuous[n][0].startswith('e1'):\n","            in_lf0_idx = n + len(binary)\n","            break\n","\n","    print(f'in_rest_idx: {in_rest_idx}\\nin_lf0_idx: {in_lf0_idx}')\n","\n","    config['relative_f0'] = False\n","\n","    acoustic_data['sample_rate'] = int(sample_rate)\n","    acoustic_data['in_lf0_idx'] = in_lf0_idx\n","    acoustic_data['in_rest_idx'] = in_rest_idx\n","    acoustic_data['out_lf0_idx'] = 180\n","\n","    acoustic['netG']['in_lf0_idx'] = in_lf0_idx\n","    acoustic['netG']['out_lf0_idx'] = 180\n","    acoustic['netG']['in_lf0_min'] = None\n","    acoustic['netG']['in_lf0_max'] = None\n","    acoustic['netG']['out_lf0_mean'] = None\n","    acoustic['netG']['out_lf0_scale'] = None\n","\n","    acoustic_train['pitch_reg_weight'] = pitch_reg\n","    acoustic_train['pitch_reg_decay_size'] = pitch_reg_decay_size\n","    acoustic_train['use_detect_anomaly'] = False\n","else:\n","    for k in ['sample_rate', 'in_lf0_idx', 'in_rest_idx', 'out_lf0_idx']:\n","        if k in acoustic_data.keys():\n","            del acoustic_data[k]\n","\n","    for k in ['in_lf0_idx', 'out_lf0_idx', 'in_lf0_min', 'in_lf0_max', 'out_lf0_mean', 'out_lf0_scale']:\n","        if k in acoustic['netG'].keys():\n","            del acoustic['netG'][k]\n","    \n","    for k in ['pitch_reg_weight', 'pitch_reg_decay_size']:\n","        if k in acoustic_train.keys():\n","            del acoustic_train[k]\n","\n","    config['relative_f0'] = True\n","\n","# Set vibrato mode stuff\n","if vibrato_mode == 'none':\n","    config['acoustic_features'] = 'static_deltadelta'\n","    acoustic['stream_sizes'] = [180, 3, 1, 15]\n","    acoustic['has_dynamic_features'] = [True, True, False, True]\n","    acoustic['netG']['out_dim'] = 199\n","\n","    postfilter_mgc['stream_sizes'] = [60, 1, 1, 5]\n","    postfilter_mgc['has_dynamic_features'] = [False, False, False, False]\n","    postfilter_mgc_train['adv_streams'] = [True, False, False, False]\n","\n","    postfilter_bap['stream_sizes'] = [60, 1, 1, 5]\n","    postfilter_bap['has_dynamic_features'] = [False, False, False, False]\n","    postfilter_bap_train['adv_streams'] = [False, False, False, True]\n","elif vibrato_mode == 'sine':\n","    config['acoustic_features'] = 'static_deltadelta_sinevib'\n","    acoustic['stream_sizes'] = [180, 3, 1, 15, 6, 1]\n","    acoustic['has_dynamic_features'] = [True, True, False, True, True, False]\n","    acoustic['netG']['out_dim'] = 206\n","\n","    postfilter_mgc['stream_sizes'] = [60, 1, 1, 5, 2, 1]\n","    postfilter_mgc['has_dynamic_features'] = [False, False, False, False, False, False]\n","    postfilter_mgc_train['adv_streams'] = [True, False, False, False, False, False]\n","    \n","    postfilter_bap['stream_sizes'] = [60, 1, 1, 5, 2, 1]\n","    postfilter_bap['has_dynamic_features'] = [False, False, False, False, False, False]\n","    postfilter_bap_train['adv_streams'] = [False, False, False, True, False, False]\n","else:\n","    config['acoustic_features'] = 'static_deltadelta_diffvib'\n","    acoustic['stream_sizes'] = [180, 3, 1, 15, 3]\n","    acoustic['has_dynamic_features'] = [True, True, False, True, True]\n","    acoustic['netG']['out_dim'] = 202\n","\n","    postfilter_mgc['stream_sizes'] = [60, 1, 1, 5, 1]\n","    postfilter_mgc['has_dynamic_features'] = [False, False, False, False, False]\n","    postfilter_mgc_train['adv_streams'] = [True, False, False, False, False]\n","    \n","    postfilter_bap['stream_sizes'] = [60, 1, 1, 5, 1]\n","    postfilter_bap['has_dynamic_features'] = [False, False, False, False, False]\n","    postfilter_bap_train['adv_streams'] = [False, False, False, True, False]\n","\n","write_yaml(config, enunu_base + '/config.yaml')\n","\n","write_yaml(acoustic_data, acoustic_base + '/data/myconfig.yaml')\n","\n","write_yaml(acoustic_train, acoustic_base + '/train/myconfig.yaml')\n","write_yaml(duration_train, duration_base + '/train/myconfig.yaml')\n","write_yaml(timelag_train, timelag_base + '/train/myconfig.yaml')\n","\n","write_yaml(acoustic, acoustic_base + '/model/acoustic_custom.yaml')\n","write_yaml(duration, duration_base + '/model/duration_custom.yaml')\n","write_yaml(timelag, timelag_base + '/model/timelag_custom.yaml')\n","\n","write_yaml(postfilter_mgc, postfilter_base + '/model/postfilter_mgc.yaml')\n","write_yaml(postfilter_mgc_train, postfilter_base + '/train/mgc.yaml')\n","write_yaml(postfilter_bap, postfilter_base + '/model/postfilter_bap.yaml')\n","write_yaml(postfilter_bap_train, postfilter_base + '/train/bap.yaml')\n"],"metadata":{"cellView":"form","id":"6S3PfC9H2NAY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title # Step 5: Change Training Parameters\n","\n","#@markdown ---\n","#@markdown ### Resume from checkpoint\n","#@markdown If resuming from a checkpoint duh.\n","resume_from_checkpoint = False #@param {type: \"boolean\"}\n","resume_loc = '/content/the_model' #@param {type: \"string\"}\n","\n","#@markdown ---\n","#@markdown ### Segmentation and Checkpoint Intervals\n","#@markdown How much the data is split and how many checkpoints are saved while training (roughly)\n","middle_frequency = 3 #@param {type: \"integer\"}\n","checkpoints = 8 #@param {type: \"integer\"}\n","checkpoints = max(checkpoints, 1)\n","\n","#@markdown ---\n","#@markdown ### F0/Pitch Estimation Settings\n","#@markdown Range of F0 detection. This is in Hz but you can reference [this](https://pages.mtu.edu/~suits/notefreqs.html) for the pitches.\n","f0_floor = 150 #@param {type: \"number\"}\n","f0_ceil = 700 #@param {type: \"number\"}\n","\n","#@markdown This is for avoiding conflicts in F0 estimation in voiced/unvoiced parts. Requires your hed file to have `C-VUV_Voiced` and `C-VUV_Unvoiced`\n","correct_vuv = True #@param {type: \"boolean\"}\n","\n","#@markdown ---\n","#@markdown ### Acoustic Settings\n","acoustic_epochs = 64 #@param {type: \"integer\"}\n","acoustic_hidden_dim = 256 #@param {type: \"integer\"}\n","acoustic_num_layers = 6 #@param {type: \"integer\"}\n","acoustic_dropout = 0.1 #@param {type: \"slider\", min: 0, max: 1, step: 0.1}\n","acoustic_batch_size = 8 #@param {type: \"integer\"}\n","acoustic_interval = acoustic_epochs // checkpoints\n","\n","#@markdown ---\n","#@markdown ### Duration Settings\n","duration_epochs = 128 #@param {type: \"integer\"}\n","duration_hidden_dim = 256 #@param {type: \"integer\"}\n","duration_num_layers = 3 #@param {type: \"integer\"}\n","duration_dropout = 0.5 #@param {type: \"slider\", min: 0, max: 1, step: 0.1}\n","duration_batch_size = 8 #@param {type: \"integer\"}\n","duration_interval = duration_epochs // checkpoints\n","\n","#@markdown ---\n","#@markdown ### Timelag Settings\n","timelag_epochs = 128 #@param {type: \"integer\"}\n","timelag_hidden_dim = 256 #@param {type: \"integer\"}\n","timelag_num_layers = 3 #@param {type: \"integer\"}\n","timelag_dropout = 0.5 #@param {type: \"slider\", min: 0, max: 1, step: 0.1}\n","timelag_batch_size = 8 #@param {type: \"integer\"}\n","timelag_interval = timelag_epochs // checkpoints\n","\n","#@markdown ---\n","#@markdown ### Postfilter Settings\n","postfilter_epochs = 256 #@param {type: \"integer\"}\n","postfilter_batch_size = 8 #@param {type: \"integer\"}\n","postfilter_interval = postfilter_epochs // checkpoints\n","\n","if resume_from_checkpoint:\n","    config['pretrained_expdir'] = resume_loc\n","else:\n","    config['pretrained_expdir'] = None\n","\n","config['stage0']['middle_frequency'] = middle_frequency\n","\n","config['f0_floor'] = f0_floor\n","config['f0_ceil'] = f0_ceil\n","config['correct_vuv'] = correct_vuv\n","\n","write_yaml(config, enunu_base + '/config.yaml')\n","\n","acoustic_data['batch_size'] = acoustic_batch_size\n","if acoustic_model.endswith('FFConvLSTM'):\n","    for k in ['hidden_dim', 'num_layers']:\n","        if k in acoustic['netG'].keys():\n","            del acoustic['netG'][k]\n","\n","    acoustic['netG']['ff_hidden_dim'] = acoustic_hidden_dim\n","    acoustic['netG']['conv_hidden_dim'] = acoustic_hidden_dim\n","    acoustic['netG']['lstm_hidden_dim'] = acoustic_hidden_dim\n","    acoustic['netG']['num_lstm_layers'] = acoustic_num_layers\n","else:\n","    for k in ['ff_hidden_dim', 'conv_hidden_dim', 'lstm_hidden_dim', 'num_lstm_layers']:\n","        if k in acoustic['netG'].keys():\n","            del acoustic['netG'][k]\n","            \n","    acoustic['netG']['hidden_dim'] = acoustic_hidden_dim\n","    acoustic['netG']['num_layers'] = acoustic_num_layers\n","acoustic['netG']['dropout'] = acoustic_dropout\n","acoustic_train['nepochs'] = acoustic_epochs\n","acoustic_train['checkpoint_epoch_interval'] = acoustic_interval\n","\n","if acoustic_model in ['Conv1dResnet', 'Conv1dResnetSAR', 'MDN', 'ResF0Conv1dResnet']:\n","    del acoustic['netG']['dropout']\n","\n","duration_data['batch_size'] = duration_batch_size\n","duration['netG']['hidden_dim'] = duration_hidden_dim\n","duration['netG']['num_layers'] = duration_num_layers\n","duration['netG']['dropout'] = duration_dropout\n","duration_train['nepochs'] = duration_epochs\n","duration_train['checkpoint_epoch_interval'] = duration_interval\n","\n","timelag_data['batch_size'] = timelag_batch_size\n","timelag['netG']['hidden_dim'] = timelag_hidden_dim\n","timelag['netG']['num_layers'] = timelag_num_layers\n","timelag['netG']['dropout'] = timelag_dropout\n","timelag_train['nepochs'] = timelag_epochs\n","timelag_train['checkpoint_epoch_interval'] = timelag_interval\n","\n","postfilter_data['batch_size'] = postfilter_batch_size\n","postfilter_mgc_train['nepochs'] = postfilter_epochs\n","postfilter_mgc_train['checkpoint_epoch_interval'] = postfilter_interval\n","postfilter_bap_train['nepochs'] = postfilter_epochs\n","postfilter_bap_train['checkpoint_epoch_interval'] = postfilter_interval\n","\n","\n","write_yaml(acoustic_data, acoustic_base + '/data/myconfig.yaml')\n","write_yaml(acoustic_train, acoustic_base + '/train/myconfig.yaml')\n","write_yaml(acoustic, acoustic_base + '/model/acoustic_custom.yaml')\n","\n","write_yaml(duration_data, duration_base + '/data/myconfig.yaml')\n","write_yaml(duration_train, duration_base + '/train/myconfig.yaml')\n","write_yaml(duration, duration_base + '/model/duration_custom.yaml')\n","\n","write_yaml(timelag_data, timelag_base + '/data/myconfig.yaml')\n","write_yaml(timelag_train, timelag_base + '/train/myconfig.yaml')\n","write_yaml(timelag, timelag_base + '/model/timelag_custom.yaml')\n","\n","write_yaml(postfilter_data, postfilter_base + '/data/myconfig.yaml')\n","write_yaml(postfilter_mgc_train, postfilter_base + '/train/mgc.yaml')\n","write_yaml(postfilter_bap_train, postfilter_base + '/train/bap.yaml')"],"metadata":{"cellView":"form","id":"MikDMBwRo_Pg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training\n","Finally..."],"metadata":{"id":"VuQ8HhVmNMaC"}},{"cell_type":"code","source":["#@title # Tensorboard\n","\n","#@markdown Run this if you wanna see funny graphs I guess. If it's not showing, here's what you do:\n","\n","#@markdown ## Chromium\n","#@markdown - Enable third party cookies.\n","\n","#@markdown ## Firefox\n","#@markdown - Disable Enhanced Tracking for Google Colab.\n","\n","#@markdown **TIP:** You can set a reload interval if you click the settings at the top to get updates every 30 seconds or so\n","%load_ext tensorboard\n","import datetime\n","from tensorboard import notebook\n","!mkdir /content/enunu_training_kit/train/tensorboard/\n","%tensorboard --logdir /content/enunu_training_kit/train/tensorboard/\n"],"metadata":{"id":"e3MMtQ6iA-7K","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title # Step 6: Data Prep, Feature Extraction, Train main models\n","\n","#@markdown YEAAYEAAYEAAAEEAAAAYYYEEAAAAAYYOOOOUUUUUUWOoooaahhh\n","\n","#@markdown This only trains acoustic, duration and timelag\n","\n","starting_stage = 0 #@param {type: \"slider\", min: 0, max: 5, step: 1}\n","stopping_stage = 5 #@param {type: \"slider\", min: 0, max: 5, step: 1}\n","\n","#@markdown ---\n","#@markdown NO SPACES !!! OR JAPANESE CHARACTERS !!!\n","singer_name = 'Unnamed' #@param {type: \"string\"}\n","\n","config['spk'] = singer_name\n","config['tag'] = 'CeVOX_Cantano_Al_Kit'\n","enuconfig['stats_dir'] = f'dump/{singer_name}/norm'\n","enuconfig['model_dir'] = f'exp/{singer_name}_CeVOX_Cantano_Al_Kit'\n","\n","write_yaml(config, enunu_base + '/config.yaml')\n","write_yaml(enuconfig, enunu_base + '/enuconfig.yaml')\n","\n","%cd \"/content/enunu_training_kit/train\"\n","if acoustic_model.startswith('Res'):\n","    print('ResF0 Mode')\n","    !bash run_resf0.sh --stage $starting_stage --stop_stage $stopping_stage\n","else:\n","    !bash run.sh --stage $starting_stage --stop_stage $stopping_stage"],"metadata":{"cellView":"form","id":"H5EjIiwwOH1P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title # Step 7: Train postfilter\n","\n","#@markdown YEAAYEAAYEAAAEEAAAAYYYEEAAAAAYYOOOOUUUUUUWOoooaahhh part 2\n","\n","#@markdown For postfilter. Trains slowly !!!!!\n","\n","starting_stage = 7 #@param {type: \"slider\", min: 7, max: 10, step: 1}\n","stopping_stage = 10 #@param {type: \"slider\", min: 7, max: 10, step: 1}\n","\n","%cd \"/content/enunu_training_kit/train\"\n","if acoustic_model.startswith('Res'):\n","    print('ResF0 Mode')\n","    !bash run_resf0.sh --stage $starting_stage --stop_stage $stopping_stage\n","else:\n","    !bash run.sh --stage $starting_stage --stop_stage $stopping_stage"],"metadata":{"cellView":"form","id":"5L8riVg0BZFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title # Step 8: Package Model\n","%cd \"/content/enunu_training_kit/train\"\n","!bash run.sh --stage 99 --stop_stage 99\n","%cd /content/\n","store_on_drive = True #@param {type: \"boolean\"}\n","clean_up_model = True #@param {type: \"boolean\"}\n","from datetime import datetime, timezone\n","import glob\n","\n","time_now = datetime.now(timezone.utc).strftime('%Y-%m-%d %H-%M-%S')\n","\n","archive_name = f'{singer_name}_{time_now}'\n","\n","if clean_up_model:\n","    !rm -f /content/enunu_training_kit/train/release/{singer_name}_---/exp/{singer_name}_CeVOX_Cantano_Al_Kit/*/checkpoint*\n","    !rm -f /content/enunu_training_kit/train/release/{singer_name}_---/exp/{singer_name}_CeVOX_Cantano_Al_Kit/*/epoch*\n","    for model_loc in glob.glob(enunu_base + f'/release/{singer_name}_---/exp/{singer_name}_CeVOX_Cantano_Al_Kit/*/model.yaml'):\n","        model_yaml = load_yaml(model_loc)\n","        for k in ['init_type']:\n","            if k in model_yaml['netG'].keys():\n","                del model_yaml['netG'][k]\n","        write_yaml(model_yaml, model_loc)\n","\n","%cd /content/enunu_training_kit/train/release\n","!zip -r \"/content/{archive_name}.zip\" ./{singer_name}_---\n","\n","if store_on_drive:\n","    if not os.path.exists('/content/drive/MyDrive/NNSVS_Release_Models'):\n","        !mkdir /content/drive/MyDrive/NNSVS_Release_Models\n","    \n","    !mv -v \"/content/{archive_name}.zip\" /content/drive/MyDrive/NNSVS_Release_Models\n","\n","#clear_output()\n","print('Done!')"],"metadata":{"id":"5pYaRbzTRXt8","cellView":"form"},"execution_count":null,"outputs":[]}]}